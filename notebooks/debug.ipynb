{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eae0fc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import chromadb\n",
    "from openai import OpenAI\n",
    "from chromadb.utils import embedding_functions\n",
    "import streamlit as st\n",
    "\n",
    "# Load environment\n",
    "load_dotenv()\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Load documents from directory\n",
    "def load_documents_from_directory(directory_path):\n",
    "    documents = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".md\"):\n",
    "            with open(os.path.join(directory_path, filename), \"r\", encoding=\"utf-8\") as file:\n",
    "                documents.append({\"id\": filename, \"text\": file.read()})\n",
    "    return documents\n",
    "\n",
    "def split_text(text, chunk_size=1000, chunk_overlap=20):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        chunks.append(text[start:end])\n",
    "        start = end - chunk_overlap\n",
    "    return chunks\n",
    "\n",
    "# This function now receives the OpenAI client\n",
    "def get_openai_embedding(text, openai_client):\n",
    "    response = openai_client.embeddings.create(input=text, model=\"text-embedding-3-small\")\n",
    "    embedding = response.data[0].embedding\n",
    "    return embedding\n",
    "\n",
    "def create_embeddings():\n",
    "    # Initialize consistent Chroma and OpenAI clients\n",
    "    chroma_client = chromadb.PersistentClient(path=\"./data/chroma_persistent_storage\")\n",
    "    openai_client = OpenAI(api_key=openai_key)\n",
    "\n",
    "    collection_name = \"document_qa_collection\"\n",
    "\n",
    "    # Delete old collection (if it exists)\n",
    "    try:\n",
    "        chroma_client.delete_collection(name=collection_name)\n",
    "        print(\"✅ Deleted previous collection.\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Could not delete collection: {e}\")\n",
    "\n",
    "    # Initialize embedding function for Chroma\n",
    "    openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "        api_key=openai_key,\n",
    "        model_name=\"text-embedding-3-small\",\n",
    "    )\n",
    "\n",
    "    # Recreate collection with embedding function\n",
    "    collection = chroma_client.get_or_create_collection(\n",
    "        name=collection_name,\n",
    "        embedding_function=openai_ef\n",
    "    )\n",
    "\n",
    "    # Load markdown files\n",
    "    directory_path = \"./data/pages\"\n",
    "    if not os.path.exists(directory_path):\n",
    "        raise FileNotFoundError(f\"❌ Directory '{directory_path}' not found. Run layout analysis first.\")\n",
    "\n",
    "    documents = load_documents_from_directory(directory_path)\n",
    "    print(f\"📄 Loaded {len(documents)} pages\")\n",
    "\n",
    "    # Split text into chunks\n",
    "    chunked_documents = []\n",
    "    for doc in documents:\n",
    "        chunks = split_text(doc['text'])\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            chunked_documents.append({\"id\": f\"{doc['id']}_chunk{i+1}\", \"text\": chunk})\n",
    "\n",
    "    print(f\"✂️ Split into {len(chunked_documents)} chunks\")\n",
    "\n",
    "    # Generate embeddings and store\n",
    "    for doc in chunked_documents:\n",
    "        print(\"🧠 Generating embeddings...\")\n",
    "        doc[\"embedding\"] = get_openai_embedding(doc[\"text\"], openai_client)\n",
    "\n",
    "    for doc in chunked_documents:\n",
    "        print(\"📥 Inserting chunk into ChromaDB...\")\n",
    "        collection.upsert(\n",
    "            ids=[doc[\"id\"]],\n",
    "            documents=[doc[\"text\"]],\n",
    "            embeddings=[doc[\"embedding\"]]\n",
    "        )\n",
    "\n",
    "    st.success(\"✅ Embeddings generated and stored successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1232583a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Could not delete collection: Collection document_qa_collection does not exist.\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "attempt to write a readonly database",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 21\u001b[0m\n\u001b[1;32m     15\u001b[0m openai_ef \u001b[38;5;241m=\u001b[39m embedding_functions\u001b[38;5;241m.\u001b[39mOpenAIEmbeddingFunction(\n\u001b[1;32m     16\u001b[0m     api_key\u001b[38;5;241m=\u001b[39mopenai_key,\n\u001b[1;32m     17\u001b[0m     model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-embedding-3-small\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Recreate collection with embedding function\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m collection \u001b[38;5;241m=\u001b[39m \u001b[43mchroma_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_or_create_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopenai_ef\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/projects/diploma_project/topological rag/myenv/lib/python3.10/site-packages/chromadb/api/client.py:237\u001b[0m, in \u001b[0;36mClient.get_or_create_collection\u001b[0;34m(self, name, metadata, embedding_function, data_loader)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_or_create_collection\u001b[39m(\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    235\u001b[0m     data_loader: Optional[DataLoader[Loadable]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    236\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Collection:\n\u001b[0;32m--> 237\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_server\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_or_create_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/projects/diploma_project/topological rag/myenv/lib/python3.10/site-packages/chromadb/telemetry/opentelemetry/__init__.py:127\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Documents/projects/diploma_project/topological rag/myenv/lib/python3.10/site-packages/chromadb/api/segment.py:217\u001b[0m, in \u001b[0;36mSegmentAPI.get_or_create_collection\u001b[0;34m(self, name, metadata, embedding_function, data_loader, tenant, database)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;129m@trace_method\u001b[39m(\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSegmentAPI.get_or_create_collection\u001b[39m\u001b[38;5;124m\"\u001b[39m, OpenTelemetryGranularity\u001b[38;5;241m.\u001b[39mOPERATION\n\u001b[1;32m    204\u001b[0m )\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    215\u001b[0m     database: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m DEFAULT_DATABASE,\n\u001b[1;32m    216\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Collection:\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m        \u001b[49m\u001b[43mget_or_create\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/projects/diploma_project/topological rag/myenv/lib/python3.10/site-packages/chromadb/telemetry/opentelemetry/__init__.py:127\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Documents/projects/diploma_project/topological rag/myenv/lib/python3.10/site-packages/chromadb/api/segment.py:167\u001b[0m, in \u001b[0;36mSegmentAPI.create_collection\u001b[0;34m(self, name, metadata, embedding_function, data_loader, get_or_create, tenant, database)\u001b[0m\n\u001b[1;32m    163\u001b[0m check_index_name(name)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m uuid4()\n\u001b[0;32m--> 167\u001b[0m coll, created \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sysdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdimension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_or_create\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_or_create\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created:\n\u001b[1;32m    178\u001b[0m     segments \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager\u001b[38;5;241m.\u001b[39mcreate_segments(coll)\n",
      "File \u001b[0;32m~/Documents/projects/diploma_project/topological rag/myenv/lib/python3.10/site-packages/chromadb/telemetry/opentelemetry/__init__.py:127\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Documents/projects/diploma_project/topological rag/myenv/lib/python3.10/site-packages/chromadb/db/mixins/sysdb.py:267\u001b[0m, in \u001b[0;36mSqlSysDB.create_collection\u001b[0;34m(self, id, name, metadata, dimension, get_or_create, tenant, database)\u001b[0m\n\u001b[1;32m    265\u001b[0m sql, params \u001b[38;5;241m=\u001b[39m get_sql(insert_collection, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameter_format())\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 267\u001b[0m     \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munique_constraint_error() \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UniqueConstraintError(\n\u001b[1;32m    270\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCollection \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcollection[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m already exists\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    271\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mOperationalError\u001b[0m: attempt to write a readonly database"
     ]
    }
   ],
   "source": [
    "chroma_client = chromadb.PersistentClient(path=\"./data/chroma_persistent_storage\")\n",
    "openai_client = OpenAI(api_key=openai_key)\n",
    "\n",
    "collection_name = \"document_qa_collection\"\n",
    "client = chromadb.PersistentClient(path=\"./data/chroma_persistent_storage\")\n",
    "client.get_or_create_collection(name=\"init_collection\")\n",
    "try:\n",
    "    chroma_client.delete_collection(name=collection_name)\n",
    "    print(\"✅ Deleted previous collection.\")\n",
    "except Exception as e:\n",
    "    \n",
    "    print(f\"⚠️ Could not delete collection: {e}\")\n",
    "    \n",
    "# Initialize embedding function for Chroma\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "    api_key=openai_key,\n",
    "    model_name=\"text-embedding-3-small\",\n",
    ")\n",
    "\n",
    "# Recreate collection with embedding function\n",
    "collection = chroma_client.get_or_create_collection(\n",
    "    name=collection_name,\n",
    "    embedding_function=openai_ef\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8bfa0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Deleted previous collection.\n",
      "📄 Loaded 11 pages\n",
      "✂️ Split into 71 chunks\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n",
      "🧠 Generating embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-28 20:34:43.382 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-28 20:34:43.383 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n",
      "📥 Inserting chunk into ChromaDB...\n"
     ]
    }
   ],
   "source": [
    "create_embeddings()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
